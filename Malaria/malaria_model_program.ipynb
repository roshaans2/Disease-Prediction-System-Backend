{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d190c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries as shown below\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a1e02ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = r'C:\\Users\\ROSHAAN\\Desktop\\Malaria\\Dataset\\Train'\n",
    "valid_path = r'C:\\Users\\ROSHAAN\\Desktop\\Malaria\\Dataset\\Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9566e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Vgg 16 library as shown below and add preprocessing layer to the front of VGG\n",
    "# Here we will be using imagenet weights\n",
    "\n",
    "mobilnet = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc638f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# don't train existing weights\n",
    "for layer in mobilnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fb903d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # useful for getting number of output classes\n",
    "folders = glob('Dataset/Train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccdaf2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dataset/Train\\\\Parasite', 'Dataset/Train\\\\Uninfected']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5a11214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(mobilnet.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a361d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=mobilnet.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86a53807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,074,562\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b947c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deaf20f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 16)      208       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 32)      2080      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 64)        8256      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 50176)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 500)               25088500  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 1002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,100,046\n",
      "Trainable params: 25,100,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Create Model from scratch using CNN\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9d51aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfd83f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Image Data Generator to import the images from the dataset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0c82c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you provide the same target size as initialied for the image size\n",
    "training_set = train_datagen.flow_from_directory('Dataset/Train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c317625d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x11116d52ce0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dd2b6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('Dataset/Test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6556be86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROSHAAN\\AppData\\Local\\Temp\\ipykernel_14688\\4102162479.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  r = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 16s 1s/step - loss: 1.2481 - accuracy: 0.5312 - val_loss: 0.7815 - val_accuracy: 0.3358\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.6696 - accuracy: 0.5913 - val_loss: 0.6887 - val_accuracy: 0.5448\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 12s 933ms/step - loss: 0.6233 - accuracy: 0.6418 - val_loss: 1.1194 - val_accuracy: 0.3209\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 12s 941ms/step - loss: 0.5571 - accuracy: 0.6827 - val_loss: 1.1264 - val_accuracy: 0.3284\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 12s 929ms/step - loss: 0.4612 - accuracy: 0.7692 - val_loss: 1.6168 - val_accuracy: 0.3209\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 12s 949ms/step - loss: 0.4835 - accuracy: 0.7380 - val_loss: 1.3768 - val_accuracy: 0.3507\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 12s 952ms/step - loss: 0.5018 - accuracy: 0.7452 - val_loss: 0.7963 - val_accuracy: 0.4627\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 12s 935ms/step - loss: 0.4583 - accuracy: 0.7596 - val_loss: 1.0768 - val_accuracy: 0.3358\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 12s 949ms/step - loss: 0.4208 - accuracy: 0.7788 - val_loss: 0.7869 - val_accuracy: 0.4254\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 12s 942ms/step - loss: 0.3903 - accuracy: 0.7933 - val_loss: 1.0812 - val_accuracy: 0.3284\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.3922 - accuracy: 0.7957 - val_loss: 0.7633 - val_accuracy: 0.4851\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.2860 - accuracy: 0.8750 - val_loss: 0.7600 - val_accuracy: 0.5299\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 13s 972ms/step - loss: 0.2623 - accuracy: 0.9038 - val_loss: 0.8779 - val_accuracy: 0.5224\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 13s 962ms/step - loss: 0.2880 - accuracy: 0.8966 - val_loss: 0.7734 - val_accuracy: 0.6119\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 13s 963ms/step - loss: 0.3366 - accuracy: 0.8365 - val_loss: 0.6424 - val_accuracy: 0.5896\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 13s 956ms/step - loss: 0.2489 - accuracy: 0.9279 - val_loss: 0.5645 - val_accuracy: 0.6866\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 13s 971ms/step - loss: 0.1800 - accuracy: 0.9351 - val_loss: 0.4213 - val_accuracy: 0.7836\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 13s 967ms/step - loss: 0.1675 - accuracy: 0.9519 - val_loss: 0.5510 - val_accuracy: 0.7463\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 13s 952ms/step - loss: 0.1376 - accuracy: 0.9567 - val_loss: 0.3873 - val_accuracy: 0.8134\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 13s 962ms/step - loss: 0.1154 - accuracy: 0.9688 - val_loss: 0.4401 - val_accuracy: 0.8060\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0936 - accuracy: 0.9784 - val_loss: 0.2933 - val_accuracy: 0.8806\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0971 - accuracy: 0.9736 - val_loss: 0.3128 - val_accuracy: 0.8731\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 13s 960ms/step - loss: 0.0778 - accuracy: 0.9736 - val_loss: 0.2534 - val_accuracy: 0.8731\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 13s 996ms/step - loss: 0.0932 - accuracy: 0.9639 - val_loss: 0.2508 - val_accuracy: 0.8955\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 13s 972ms/step - loss: 0.0586 - accuracy: 0.9856 - val_loss: 0.3474 - val_accuracy: 0.8582\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 13s 978ms/step - loss: 0.0673 - accuracy: 0.9736 - val_loss: 0.2705 - val_accuracy: 0.9104\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 13s 970ms/step - loss: 0.0792 - accuracy: 0.9784 - val_loss: 0.2306 - val_accuracy: 0.9104\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 13s 994ms/step - loss: 0.0618 - accuracy: 0.9808 - val_loss: 0.4054 - val_accuracy: 0.8582\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.0655 - accuracy: 0.9856 - val_loss: 0.3862 - val_accuracy: 0.8657\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.0540 - accuracy: 0.9832 - val_loss: 0.4009 - val_accuracy: 0.8657\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 13s 991ms/step - loss: 0.0435 - accuracy: 0.9880 - val_loss: 0.1659 - val_accuracy: 0.9403\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 13s 985ms/step - loss: 0.0365 - accuracy: 0.9904 - val_loss: 0.2187 - val_accuracy: 0.9179\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 13s 970ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.1722 - val_accuracy: 0.9403\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 15s 1s/step - loss: 0.0535 - accuracy: 0.9832 - val_loss: 0.3391 - val_accuracy: 0.8731\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 13s 991ms/step - loss: 0.0501 - accuracy: 0.9832 - val_loss: 0.1872 - val_accuracy: 0.9254\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 13s 977ms/step - loss: 0.0248 - accuracy: 0.9952 - val_loss: 0.2522 - val_accuracy: 0.9254\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0495 - accuracy: 0.9856 - val_loss: 0.3487 - val_accuracy: 0.8582\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0385 - accuracy: 0.9856 - val_loss: 0.2143 - val_accuracy: 0.9030\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 13s 980ms/step - loss: 0.0335 - accuracy: 0.9928 - val_loss: 0.3170 - val_accuracy: 0.8881\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 13s 984ms/step - loss: 0.0268 - accuracy: 0.9952 - val_loss: 0.1941 - val_accuracy: 0.9328\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 13s 987ms/step - loss: 0.0307 - accuracy: 0.9880 - val_loss: 0.5993 - val_accuracy: 0.8582\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.0531 - accuracy: 0.9688 - val_loss: 0.3630 - val_accuracy: 0.8806\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 13s 985ms/step - loss: 0.0752 - accuracy: 0.9760 - val_loss: 0.7943 - val_accuracy: 0.8507\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 13s 983ms/step - loss: 0.0717 - accuracy: 0.9712 - val_loss: 0.4756 - val_accuracy: 0.8731\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 13s 977ms/step - loss: 0.0491 - accuracy: 0.9832 - val_loss: 0.1788 - val_accuracy: 0.9328\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 13s 1000ms/step - loss: 0.0282 - accuracy: 0.9904 - val_loss: 0.1225 - val_accuracy: 0.9478\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 13s 979ms/step - loss: 0.0181 - accuracy: 0.9952 - val_loss: 0.2425 - val_accuracy: 0.9254\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0248 - accuracy: 0.9952 - val_loss: 0.2376 - val_accuracy: 0.9179\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 13s 989ms/step - loss: 0.0496 - accuracy: 0.9808 - val_loss: 0.2537 - val_accuracy: 0.9030\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.0500 - accuracy: 0.9832 - val_loss: 0.2076 - val_accuracy: 0.9104\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "# Run the cell. It will take some time to execute\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=50,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "541442b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it as a h5 file\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('model111.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aca3dee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c4c7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('model111.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93f365b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.load_img('Dataset/Test/Uninfected/2.png',target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a3799fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1c035a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b48d5f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.expand_dims(x,axis=0)\n",
    "img_data=preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fe37f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73654b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
